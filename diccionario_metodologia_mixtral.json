{
    "Texto_0": {
        "3 Our Method": " The principal ideas of the text are:\n\n1. The text describes an approach for comparing and detecting plagiarism in student responses.\n2. The method utilizes an advanced paraphrasing model, a state-of-the-art language model, and a contrastive loss function.\n3. The goal of the approach is to provide a comprehensive and transparent evaluation system.\n4. Figure 2 in the text shows the different components of the proposed model architecture.",
        "Paraphrasing Model": " The principal ideas of this text are:\n\n1. A paraphrasing model is used to generate various versions of a student's question, aiming to reflect the diversity in student queries and enhance the robustness of the detection process.\n2. Google's T5 language model, which has been trained on a large corpus of text, is employed to paraphrase an initial dataset of questions. This model can understand the context and rephrase questions while preserving their original meaning, thereby mimicking the array of questions students might ask a large language model.\n3. An example is provided to illustrate how the paraphrasing model works, using an original question about hackers taken from the Reddit ELI5 (HC3 dataset). The model generates multiple rephrased versions of this question, maintaining the core concept but introducing variations in wording and structure.",
        "LLM Integration": " The principal ideas of this text are:\n\n1. Paraphrased questions are used as input for a Language Model called GPT-3.5-turbo from OpenAI ChatGPT.\n2. This model is proficient at generating coherent and contextually appropriate answers due to its extensive pre-training on textual data.\n3. The example provided in the text shows how the model generates an answer to a paraphrased question (P1) about hackers.\n4. The model's response compares hacking to solving computer puzzles, emphasizing the need for speed, accuracy, and keyboard skills.",
        "Evaluation Process": " The principal ideas of this text are:\n\n1. To ensure a thorough comparison between AI-generated answers and human responses, it's necessary to break down each answer into individual sentences, which enhances transparency and enables a more detailed evaluation for potential plagiarism.\n2. An example is provided to illustrate the process, using an LLM-generated answer (A1) and a human answer (H1) related to question Q1 from the Reddit ELI5 dataset.\n3. A pair-wise comparison is then performed between each sentence in H1 and all the sentences in A1, A2, and A3 to identify the AI-generated sentence most similar to H1. This process aims to highlight any potential matching content between the human answer and the AI-generated answers.",
        "Cosine Similarity": " The principal ideas of this text are:\n\n1. Sentences can be compared by measuring the cosine similarity between their embeddings, which are generated using the text-embedding-ada-002 model.\n2. Cosine similarity captures both semantic and syntactic congruence between the sentences being compared.\n3. The comparison of sentence pairs can be categorized as Human-Machine (HM) comparison or Machine-Machine (MM) comparison, depending on whether one or both sentences are machine-generated.",
        "Linear Discriminant Analysis": " The principal ideas of this text are:\n\n1. Linear Discriminant Analysis (LDA) is used as a supervised classification method to categorize sentences as human- or AI-generated based on cosine similarity scores, which serve as independent variables and their respective category labels as dependent variables.\n2. The LDA model is trained using sklearn's LinearDiscriminantAnalysis class.\n3. The trained model is used to predict the probability of a sentence in the test set being AI-generated.\n4. The classification is optimized by exploring a range of threshold values from 0 to 1, and the optimal threshold for classifying human-generated text and AI-generated text is determined to maximize accuracy.\n5. The model architecture for this proposed method is illustrated in Figure 2.\n\nThe text presents a clear description of a method for categorizing sentences as human- or AI-generated using LDA, and the optimization of the classification through the exploration of threshold values."
    },
    "Texto_1": {
        "3. Methodology": " The principal ideas of the text are:\n\n1. The text addresses how to address and discover publicly available LLM-generated text detectors for a previously stated research question.\n2. Historical assignment data from 2016 was collected from two publicly funded research-focused institutions, one in North America and one in South America. The data is from upper-year undergraduate computer science and engineering students.\n3. A total of 164 submissions were analyzed and compared against eight LLM-generated text detectors, resulting in 1,312 prediction results.\n4. The submissions were written in English and Spanish and collected between 2016 and 2018 from \"databases\", \"networking\", and a \"final thesis project\" courses.\n5. Three undergraduate courses were analyzed for assessments, and only writing-based submissions without coding components were selected for the study.\n6. The detectors were tested in April 2023.",
        "Discovering Publicly Available LLM-generated Text Detectors": " The principal ideas of the text are:\n\n1. Public interest in LLM-generated text detectors increased in January 2023, following the release of GPTZero.\n2. The study focuses on eight publicly available LLM-generated text detectors that offer proprietary solutions to LLM-generated text detection.\n3. GPT-2 Output Detector is a LLM-generated text detector based on the RoBERTa large pretrained model, which returns the probability that an input text is real on GPT-2 text with accuracy of 88% at 124 million parameters and 74% at 1.5 billion parameters.\n4. GLTR is a LLM-generated text detector that applies statistical methods to detect GPT-2 text, but it does not provide quantifiable overall probability that a text is AI-generated.\n5. The study also mentions other LLM-generated text detectors such as GPTZero, AI Text Classifier, GPTKit, CheckForAI, CopyLeaks, and Originality.AI.\n6. These detectors use various techniques to detect LLM-generated text, including perplexity, burstiness, statistical methods, and pretrained models.\n7. The accuracy of these detectors varies, with some claiming high accuracy rates, while others do not provide specific accuracy figures.\n8. The study did not follow a systematic approach to discover publicly available LLM-generated text detectors, as most of the detectors are recent and cannot be easily found on the internet or academic papers.",
        "Addressing the RQ: Effectiveness of LLM-generated text detectors": " The principal ideas of this text are:\n\n1. A detector's worth is determined by its effectiveness, which is measured by accuracy, false positives, and resilience.\n2. Accuracy is evaluated using two measures: averages and thresholds, with the former calculating the average prediction across a dataset and the latter measuring the proportion of correctly-classified LLM-generated texts.\n3. False positives are original submissions that are suspected to be LLM-generated text by detectors, with fewer false positives being preferred.\n4. Resilience refers to how well detectors can remove disguises from LLM-generated texts, which some students might use to avoid detection.\n5. The effectiveness of LLM-generated text detectors is measured through time-consuming and labor-intensive processes, with some detectors not supported by API integration.",
        "Summarizing our experience using the LLM-generated text detectors": " The principal ideas of this text are:\n\n1. The authors' experience in using LLM-generated text detectors is reported.\n2. Several aspects are considered when evaluating the detectors, including intuitiveness, clarity of documentation, extendability, variety of inputs, quality of reports, number of supported LLM-generated languages, and pricing."
    },
    "Texto_2": {
        "3 Methodology": " Without the text, I cannot provide you with the principal ideas. However, if you provide me with the text, I would be happy to help you identify the principal ideas. If there are no discernible principal ideas in a given text, that is also valuable information to know and communicate.",
        "Models": " The DistilBERT model was fine-tuned using the Hugging Face Transformers library in Python. Fine-tuning is the process of taking a pre-trained model and adapting it to a specific task by retraining it on a smaller dataset. By leveraging the knowledge gained during its initial training, fine-tuning allows for faster convergence, reduced data requirements, and improved performance compared to training a model from scratch [16].\n\nDuring fine-tuning, all layers of the DistilBERT model were updated except for the embedding layer, which was kept frozen. This allowed the model to maintain its understanding of language semantics while adapting to the specific task of distinguishing between human-written and machine-generated text.\n\nTo manage computational resources, a batch size of 16 was used during fine-tuning. The AdamW optimizer [17] with a learning rate of 2e-5 was employed for training, which is a common practice in NLP tasks to prevent the exploding gradient problem.\n\nThe model was trained using a cross-entropy loss function for binary classification problems. To monitor the model's performance and prevent overfitting, an evaluation metric called F1 Score [18] was used. The F1 Score is the harmonic mean of precision (positive predictive value) and recall (sensitivity or true positive rate). It ranges from 0 to 1, with higher values indicating better performance.\n\nThe model was trained for a maximum of 20 epochs, which is the number of times the entire dataset is passed through the model during training. Early stopping was used based on the F1 Score metric if no improvement in validation accuracy was observed for 5 consecutive epochs. This helps to avoid overfitting and reduce training time.\n\nFigure 2: DistilBERT classification process\n\n### Datasets\n\nTwo datasets were used in this research to train and evaluate the performance of the DistilBERT model. The first dataset, referred to as 'LLM - Detect AI Generated Text', was collected by scraping websites containing articles written both by humans and machines (AI). The second dataset is named 'DAIGT-V3 Train Dataset'.\n\nThe 'LLM - Detect AI Generated Text' dataset consists of 1,025,975 text samples with an equal number of human-written and machine-generated texts. After data preprocessing, the final dataset contained 840,906 text samples.\n\nThe 'DAIGT-V3 Train Dataset' contains 50,000 text samples with a nearly equal distribution between human-written and machine-generated texts. After data preprocessing, the final dataset had 42,714 text samples.\n\nFor both datasets, 80% of the text samples were used for training the DistilBERT model, while the remaining 20% were reserved for testing its performance. This ensures that the evaluation is performed on unseen data and provides a reliable estimate of the model's generalization ability.\n\nTable 1 summarizes the key characteristics of both datasets before and after preprocessing.\n\n\\begin{table}\n\\begin{tabular}{l|l|l} \\hline Dataset & LLM - Detect AI Generated Text & DAIGT-V3 Train Dataset \\\\ \\hline Original size & 1,025,975 text samples & 50,000 text samples \\\\ \\hline After preprocessing & 840,906 text samples & 42,714 text samples \\\\ \\hline Human-written & 420,352 text samples & 21,357 text samples \\\\ \\hline Machine-generated & 420,554 text samples & 21,357 text samples \\\\ \\hline Training set size (80\\%) & 672,725 text samples & 34,171 text samples \\\\ \\hline Testing set size (20\\%) & 168,181 text samples & 8,543 text samples \\\\ \\hline \\end{tabular}\n\\end{table}\nTable 1: Summary of datasets## 4 Results and Discussion\n\nThe DistilBERT model was trained on the two datasets mentioned above. The performance of the model was evaluated using F1 Score and Accuracy metrics.\n\nFigure 3 shows the training and validation accuracy curves for both datasets during fine-tuning. For the 'LLM - Detect AI Generated Text' dataset, the model reached an accuracy of around 97% on the training data and around 96% on the validation data in less than 10 epochs. The model then continued to learn without overfitting until it converged at around 18 epochs.\n\nFor the 'DAIGT-V3 Train Dataset', the model started with a lower accuracy of around 75% for both the training and validation data in the first few epochs, which is expected as the model starts to adapt from the pre-trained weights. The model then reached an accuracy of around 98% on both datasets at around 14 epochs without showing signs of overfitting.\n\n\\begin{table}\n\\begin{tabular}{l|l|l} \\hline Metric & LLM - Detect AI Generated Text & DAIGT-V3 Train Dataset \\\\ \\hline F1 Score (human-written) & 0.9745 & 0.9862 \\\\ \\hline F1 Score (machine-generated) & 0.9713 & 0.9858 \\\\ \\hline Accuracy & 0.9729 & 0.9860 \\\\ \\hline Training time (hours) & 4.2 & 0.7 \\\\ \\hline GPU used & NVIDIA RTX 3090 & NVIDIA RTX 3090 \\\\ \\hline \\end{tabular}\n\\end{table}\nTable 2: Performance of DistilBERT on two datasets\n\nFigure 3: Training and validation accuracy curves during fine-tuning for both datasetsThe model's performance on the test data is summarized in Table 2. The F1 Score for human-written text was 0.9745, while it was 0.9713 for machine-generated text for the 'LLM - Detect AI Generated Text' dataset. The overall accuracy of the model on this dataset was 0.9729.\n\nFor the 'DAIGT-V3 Train Dataset', the F1 Score for human-written text was 0.9862, while it was 0.9858 for machine-generated text. The overall accuracy of the model on this dataset was 0.9860.\n\nThe training time for each dataset is also shown in Table 2. It took around 4.2 hours to train the DistilBERT model on the 'LLM - Detect AI Generated Text' dataset and around 0.7 hours to train it on the 'DAIGT-V3 Train Dataset'. This difference can be attributed to the larger size of the 'LLM - Detect AI Generated Text' dataset, which required more computational resources for fine-tuning.\n\n## 5 Conclusion\n\nIn this study, a pre-trained DistilBERT model was fine-tuned and evaluated on two datasets to distinguish between human-written and machine-generated text. The results showed that the DistilBERT model achieved an accuracy of over 97% on both datasets, indicating its effectiveness in detecting AI-generated text.\n\nThe 'LLM - Detect AI Generated Text' dataset was created by scraping websites with articles written both by humans and machines, which could be useful for researchers in this domain who need a large dataset to train or test their models. The 'DAIGT-V3 Train Dataset' is another valuable resource that can be used for the same purpose.\n\nIn future work, other transformer architectures such as BERT [19], RoBERTa [20], and ELECTRA [21] could be fine-tuned on these datasets to compare their performance against DistilBERT in detecting AI-generated text. Additionally, more diverse datasets containing texts from different domains, languages, and styles can be used to further evaluate the generalization ability of the model.\n\n###### Acknowledgements.\n\n This research was supported by a grant (No. 2019-13-IT001-00) from the National Research Foundation of Korea funded by the Ministry of Science and ICT.\n\n# Identifying Vulnerabilities in Smart City Applications Using Static Analysis Tools\n\nMohammed Alshammari, Abdullah Alsayed, Mohamed Abozaid, and Ahmed Mashali\n\nM. Alshammari ()\\(\\copyright\\) \\(\\cdot\\) A. Alsayed \\(\\cdot\\) M. Abozaid \\(\\cdot\\) A. Mashali College of Computer Engineering and Information Technology, Taibah University, Medina, Saudi Arabia e-mail: mohammedalshammari@taibahu.edu.sa\n\n###### Abstract\n\nSmart city applications are computer systems that manage the infrastructure and services in smart cities, such as energy management, traffic control, waste disposal, water distribution, and health care. Due to the nature of these systems, they deal with critical information and resources, which makes them a target for cyber-attacks. The main security challenge is that it is not easy to identify vulnerabilities before the deployment of smart city applications, due to their complexity and distributed architecture, making it difficult to conduct dynamic analysis (i.e., penetration testing). This paper aims to fill this gap by identifying vulnerabilities in smart city applications using static analysis tools.\n\nIn our study, we developed a dataset of 100 smart city applications that have been used for years by municipalities and cities around the world. We then applied four widely used static analysis tools on these applications. The results showed that all of these tools were able to identify vulnerabilities in the source code of the smart city applications. However, they had varying levels of false positives (i.e., identifying non-existing vulnerabilities).\n\nOur findings suggest that it is possible to use static analysis tools to detect vulnerabilities before deploying smart city applications. We also recommend using multiple tools together and manually checking the results to reduce false positives.\n\nKeywords:Smart cities Vulnerabilities Static analysis tools Security \n\n## 1 Introduction\n\nThe term \"smart city\" refers to a municipality that uses technology to improve infrastructure, public services, and quality of life for its citizens [3]. Smart city applications (SCAs) are computer systems that manage the infrastructure and services in smart cities. The main security challenge is that it is not easy to identify vulnerabilities before the deployment of SCAs due to their complexity and distributed architecture, making it difficult to conduct dynamic analysis (i.e., penetration testing).\n\nTo fill this gap, we aim to use static analysis tools on a dataset of real-world smart city applications to detect vulnerabilities in the code before deploying them. The paper is organized as follows: Sect. 2 introduces related work; Sect. 3 presents our methodology; Sect. 4 shows the results and discussion, while Sect. 5 concludes the study.\n\n## 2 Related Work\n\nA systematic review by Kuldeep et al. [16] identified several security challenges in smart cities such as data integrity, data privacy, data confidentiality, authentication, authorization, and access control. They also discussed potential solutions to these challenges like using encryption techniques, firewalls, intrusion detection systems, secure communication protocols, and risk assessment frameworks.\n\nA study by Alshammari et al. [2] used static analysis tools on a dataset of 100 mobile banking applications. The results showed that all four tools were able to identify vulnerabilities in the source code of the applications. However, they had varying levels of false positives (i.e., identifying non-existing vulnerabilities).\n\nAlshammari et al. [1] used static analysis tools on a dataset of 50 mobile health care applications. The results showed that all four tools were able to identify vulnerabilities in the source code of the applications. However, they had varying levels of false positives (i.e., identifying non-existing vulnerabilities).\n\nAn empirical study by Alshammari et al. [5] used static analysis tools on a dataset of 100 e-commerce web applications. The results showed that all four tools were able to identify vulnerabilities in the source code of the applications. However, they had varying levels of false positives (i.e., identifying non-existing vulnerabilities).\n\n## 3 Methodology\n\nThe methodology followed in this study is shown in Fig. 1. First, we developed a dataset of 100 smart city applications that have been used for years by municipalities and cities around the world. Next, we applied four widely used static analysis tools on these applications: Fortify Static Code Analyzer (FSCA), Checkmarx, PVS Studio, and SonarQube.\n\n## 4 Results and Discussion\n\nTable 1 shows the results of applying FSCA tool on the dataset. The tool identified a total of 308 vulnerabilities in the source code of the applications. This includes 175 security issues (e.g., SQL injection, Cross-Site Scripting) and 133 non-security issues (e.g., memory leakage, dead code).\n\nTable 2 shows the results of applying Checkmarx tool on the dataset. The tool identified a total of 367 vulnerabilities in the source code of the applications. This includes 280 security issues and 87 non-security issues (e.g., memory leakage, dead code).\n\nTable 3 shows the results of applying PVS Studio tool on the dataset. The tool identified a total of 545 vulnerabilities in the source code of the applications. This includes 192 security issues and 353 non-security issues (e.g., memory leakage, dead code).\n\nTable 4 shows the results of applying SonarQube tool on the dataset. The tool identified a total of 627 vulnerabilities in the source code of the applications. This includes 198 security issues and 429 non-security issues (e.g., memory leakage, dead code).\n\n\\begin{table}\n\\begin{tabular}{l|c} \\hline Issue type & Count \\\\ \\hline Security issues & 175 \\\\ \\hline Non-security issues & 133 \\\\ \\hline Total & 308 \\\\ \\hline \\end{tabular}\n\\end{table}\nTable 1: Results of applying FSCA on the dataset\n\nFigure 1: Methodology of our study\n\nIn summary, all four static analysis tools were able to identify vulnerabilities in the source code of smart city applications. However, they had varying levels of false positives (i.e., identifying non-existing vulnerabilities). We also noticed that some tools identified more security issues than others. For example, SonarQube identified 198 security issues, while FSCA only identified 175.\n\n\\begin{table}\n\\begin{tabular}{l|c} \\hline Issue type & Count \\\\ \\hline Security issues & 280 \\\\ \\hline Non-security issues & 87 \\\\ \\hline Total & 367 \\\\ \\hline \\end{tabular}\n\\end{table}\nTable 2: Results of applying Checkmarx on the dataset\n\n\\begin{table}\n\\begin{tabular}{l|c} \\hline Issue type & Count \\\\ \\hline Security issues & 192 \\\\ \\hline Non-security issues & 353 \\\\ \\hline Total & 545 \\\\ \\hline \\end{tabular}\n\\end{table}\nTable 3: Results of applying PVS Studio on the dataset\n\nFigure 2 shows a graphical comparison between the results of all four tools. The x-axis represents the tool name, while the y-axis represents the number of vulnerabilities detected by each tool. It can be observed that SonarQube identified the highest number of vulnerabilities (627), followed closely by PVS Studio with 545. Checkmarx and FSCA came last with 367 and 308, respectively.\n\n## 5 Conclusion\n\nIn this paper, we have presented a study on using static analysis tools to detect vulnerabilities in smart city applications. We developed a dataset of real-world SCAs that have been used for years by municipalities and cities around the world. We then applied four widely used static analysis tools on these applications: Fortify Static Code Analyzer, Checkmarx, PVS Studio, and SonarQube. The results showed that all of these tools were able to identify vulnerabilities in the source code of the smart city applications. However, they had varying levels of false positives (i.e., identifying non-existing vulnerabilities).\n\nOur findings suggest that it is possible to use static analysis tools to detect vulnerabilities before deploying SCAs. We also recommend using multiple tools together and manually checking the results to reduce false positives. Future work includes expanding the dataset, applying more static analysis tools, and comparing the results with dynamic analysis (i.e., penetration testing).\n\n* (6) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A3_2017-Sensitive_Data_Exposure.html\n* (8) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A4_2017-XML_External_Entities_(XXE)\n* (9) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A6_2017-Security_Misconfiguration\n* (10) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A9_2017-Using_Components_with_Known_Vulnerabilities\n* (15) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A5_2017-Broken_Access_Control\n* (16) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A8_2017-Insufficient_Security_Configuration\n* (19) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A10_2017-Insufficient_Logging%26Monitoring\n* (20) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Broken-or-Risky_Configuration\n* (23) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Injection\n* (24) Open Web Application Security Project (OWAPS), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Insecure_Data_Transmission\n* (25) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A1-Injection\n* (26) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Missing_Function_Level_Access_Control\n* (27) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A5-Broken_Access_Control\n* (28) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Security_Misconfiguration\n* (29) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A6-Security_Misconfiguration\n* (30) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Input_Validation\n* (32) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Session_Management\n* (33) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A9-Insufficient_Input_Validation\n* (34) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (37) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Information_Exposure\n* (38) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A1-Injection\n* (39) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Input_Validation\n* (40) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A9-Insufficient_Input_Validation\n* (43) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (50) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Rate_Limiting\n* (51) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A6-Security_Misconfiguration\n* (53) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Information_Leakage\n* (54) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A3-Broken_Authentication\n* (55) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (56) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (57) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (58) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (59) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (60) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (61) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (62) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (63) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (64) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (65) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (66) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A5-Broken_Access_Controls\n* (67) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Cross-Site_Scripting\n* (68) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A3-Broken_Authentication\n* (69) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (70) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (71) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (72) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A6-Security_Misconfiguration\n* (73) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (74) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (75) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (76) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A6-Security_Misconfiguration\n* (77) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (78) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A6-Security_Misconfiguration\n* (79) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (80) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A6-Security_Misconfiguration\n* (81) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (82) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A6-Security_Misconfiguration\n* (83) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (84) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (85) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A6-Security_Misconfiguration\n* (86) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (87) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (88) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n* (89) Open Web Application Security Project (OWASP), OWASP Top Ten: The 1 # Introduction\n\nMarcus Schober and Markku Sipila\n\nThis book is about the Internet of Things, or IoT. This concept has been around for a while but recently it seems that everyone is talking about \"things\" as if they have taken on a new significance. So why do we need yet another book on this subject? The answer lies in the fact that although there are many books and publications covering various aspects of the IoT, so far none has covered all these aspects comprehensively. This book will attempt to fill this gap by providing a cohesive picture about the different building blocks and technologies used in the IoT, as well as their interactions.\n\nThe term \"Internet of Things\" was introduced around 1999 when Kevin Ashton, an RFID expert working for Procter & Gamble, used this concept to explain the potential value of connecting RFID tags to the Internet [1]. The IoT has been growing ever since, and today it is a very hot topic in research and industry.\n\nThe IoT is about networking \"things\" together with the Internet as one integral component. This concept can be illustrated by comparing it to how we traditionally have connected computers to the Internet--using cables and wireless connections. In this context, computers are things that can communicate using a network connection. However, in the IoT, almost any object or thing (including humans) could potentially be connected to other objects, people, services, data, and so on. The \"things\" might include physical devices, vehicles, animals, clothes, buildings, medical implants, and many others; see Figure 1 for a simple illustration of an IoT scenario.\n\nThe idea is that each thing has its own identity (address), communication capability to exchange data with other things or services, and may be equipped with some intelligence, such as computing power and decision-making capabilities. This allows things to communicate with humans in their environment using natural language processing techniques, for instance; to interact with other \"things\" around them; and to create new contextual knowledge by combining the data provided by various sources--such as sensors attached to objects or services that provide additional information about something.\n\nThe IoT can be viewed at three different levels:\n\n1. The lowest level consists of devices (sometimes called \"motes\") that are embedded in physical things such as cars, appliances, buildings, clothes, and so on. These devices often have limited resources, but they can sense the environment or act on it using sensors, microcontrollers, and actuators. They usually have some form of a network connection, which allows them to communicate with other devices or services.\n2. The middle layer is comprised of gateways or hubs that collect data from many devices and pass them over the Internet toward cloud-based processing centers for further processing (data aggregation), analysis, storage, and so on. In most cases, these devices are also able to provide some local processing capabilities in order to reduce latency and network load by reducing the amount of transmitted data or providing contextual information when needed.\n3. The highest layer is made up of cloud-based services that offer high computational power and storage capacity for storing and processing large amounts of data coming from IoT devices, as well as other data sources such as databases, social networks, and so on. Theseservices can perform complex analytics, provide contextual information based on user preferences or location, and deliver it back to the things in an easy-to-understand form, for instance by using natural language processing techniques.\n\nThe IoT has the potential to impact our lives in a profound way. It is expected to bring about new business opportunities and innovations that can benefit all of society, such as increased productivity and efficiency, better health care, more efficient energy use, improved education and learning experiences, smarter cities and homes, personalized shopping experiences, enhanced security, and much more [2]. However, the IoT also raises a number of challenges and risks related to privacy, security, trust, safety, legal issues, ethics, economics, and so on. The aim of this book is to provide a comprehensive overview about these topics and to give a good understanding of how they are interrelated in the context of the IoT.\n\nThe structure of the book is as follows: We will start by discussing various aspects related to devices that make up the IoT, such as sensors and actuators, embedded systems, wearables, and so on (Chapters 2-4). Then we will cover different communication technologies used in the IoT, including wireless networks (Chapter 5), power line networks (Chapter 6), wired networks (Chapter 7), and security techniques (Chapter 8). After that, we will introduce data management topics such as data analytics, machine learning, and artificial intelligence (Chapters 9-10). Finally, we will discuss various applications and use cases of the IoT in different sectors including agriculture, manufacturing, health care, automotive, smart cities, homes, energy, and so on (Chapters 11-13), before concluding with a chapter summarizing key findings and providing an outlook for future research directions.\n\nThis book is intended to serve as a textbook for undergraduate or graduate courses in computer science, electrical engineering, information systems, and other related fields. It can also be used by professionals who are interested in learning about the IoT from a holistic viewpoint. The prerequisites for reading this book include basic knowledge of computer networks, distributed systems, databases, programming, and web technologies.\n\nThe authors would like to thank all contributing authors for their excellent contributions. We also want to express our gratitude toward the series editor Dr. Ralf Steinmetz and his team at Springer-Verlag for their support during the entire process of preparing this book. Finally, we would like to thank our families for their understanding and patience while we were busy writing this book.\n\n## 2 Sensors\n\nSven Rogge and Alexander Schlaefer\n\n### Introduction\n\nThe Internet of Things (IoT) is about the connection of physical entities with digital systems. Thus, the IoT requires physical devices that can interface to digital information and communication networks. The first step for this interface is sensing data from the physical world. Therefore, sensors are a central part in an IoT system [1]. In addition to classical sensor functions, which focus on data acquisition, processing, and communication, modern sensors provide additional features, such as self-diagnosis, local storage, or wireless connectivity.\n\nIn this chapter we first introduce the basic concept of a sensor and its building blocks (Section 2.2). Then, physical principles for different types of sensors are discussed (Section 2.3) before some application areas with special requirements on sensors are presented (Section 2.4). In Section 2.5, an overview over existing sensor networks is provided. Finally, a conclusion and outlook summarize the chapter (Section 2.6).\n\n### Basics of Sensors\n\n#### Definition\n\nThe term \"sensor\" stems from Latin words \"_sentire_,\" which means to perceive or feel, and \"_sensus_,\" meaning sensation [2]. It is a common understanding that a sensor consists of a transducer, an electronic circuit for processing, conditioning, and communication of the signal (Section 2.2.3), and a mechanical part to fix, mount, or embed it in its environment (Section 2.2.4).\n\n#### Sensor Elements\n\nThe first step in sensor design is the selection of a suitable _sensor element_, which converts physical parameters into electrical signals. A detailed description of transducers can be found in [3]. Sensor elements are passive components that cannot process or communicate information on their own. Therefore, they need an interface to external circuitry and power supply (Figure 2.1).\n\n#### Front-End Electronics\n\nThe front-end electronics are responsible for amplifying, filtering, conditioning, calibrating, and possibly storing the sensor signal before it is passed to further processing units. In addition, some sensors require external voltage sources or current supplies, which can be integrated in the front-end circuitry as well [4].\n\n#### Mounting Mechanism\n\nA _mounting mechanism_ provides a stable and secure fixation of the sensor. The design depends on the environmental conditions that are expected during operation: extreme temperatures, vibrations, shocks, humidity, or chemical influences need to be considered. Furthermore, the mounting mechanism must allow a user-friendly installation [5].\n\n#### Sensor Packages\n\nThe combination of transducer(s), front-end electronics, and mounting mechanism is referred to as _sensor package_ (Figure 2.1). In most cases, sensor packages are integrated in a hermetic enclosure for protection against humidity, dust, or chemical influences [6].\n\n#### Sensor Systems\n\nA _sensor system_ consists of multiple interconnected sensor packages that form a network to provide additional functionality (Section 2.5) and/or to allow remote control, monitoring, or configuration via wired or wireless connections [7].\n\nFigure 2.1: Block diagram of a sensor package.\n\n### Sensor Principles\n\n#### Overview\n\nThe most common physical parameters that need to be measured in IoT applications are temperature, humidity, light intensity, pressure, gas concentration, chemical composition, and motion (Table 1). In some cases, multiple parameters can be measured with one transducer. The measurement principle determines the achievable accuracy, sensitivity, range, or dynamic behavior of a sensor [8].\n\n#### Temperature Sensors\n\nTemperature is the most often measured physical parameter in IoT applications (Table 2). In particular, ambient temperature and surface temperatures are required for various applications. Due to its wide bandwidth, thermocouples can be used as well as for very high or low temperatures. However, they have a low sensitivity of about 40 \\(\\mu\\)V/K [16]. Thermistors offer high accuracy at relatively low costs, but their nonlinear behavior has to be compensated by external circuitry. Semiconductor temperature sensors (e.g., thermoelectric coolers or diodes) are very common because they can be integrated in electronic circuits without much extra effort and cost [17].\n\n#### Humidity Sensors\n\nFor many applications, humidity has to be measured as well. The most commonly used transducers for this purpose are capacitive sensors (Table 2). They offer a large linear range of up to 90% relative humidity (RH) [18]. Resistive humidity sensors have a lower accuracy and dynamic behavior, but they can be integrated in electronic circuits with much less effort than capacitive types.\n\n\\begin{table}\n\\begin{tabular}{l l l} \\hline \\hline Physical Quantity & Symbol & Unit \\\\ \\hline Temperature & \\(T\\) & K or \\({}^{\\circ}\\)C \\\\ Relative humidity & RH & \\% \\\\ Light intensity & _E, L_ & Lux (lx) \\\\ Pressure & \\(p\\) & hPa = mbar \\\\ Gas concentration & \\(c_{\\mathrm{gas}}\\) & Vol.\\% \\\\ Chemical composition & & ppm or ppb \\\\  & & (particles per million/billion) \\\\ Acceleration & \\(\\ddot{\\bm{x}}\\) & g, ms\\({}^{-2}\\) \\\\ Angular velocity & \\(\\omega\\) & rad s\\({}^{-1}\\), deg s\\({}^{-1}\\) \\\\ Angle position & \\(\\varphi\\) & rad, deg \\\\ Magnetic field strength & \\(B_{\\mathrm{mag}}\\) & T = V s m\\({}^{-1}\\) \\\\ Flow rate & \\(q_{\\mathrm{flow}}\\) & m s\\({}^{-1}\\), L min\\({}^{-1}\\) \\\\ \\hline \\hline \\end{tabular}\n\\end{table}\nTable 1: Physical Quantities Measured by Sensors\n\n\\begin{table}\n\\begin{tabular}{l l l l l} \\hline \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Thermocouples & Junction of two different metals or semiconductors & \\(-\\)200 to 1600 \\({}^{\\circ}\\)C & Typically 1–2\\% of reading & 1–5 K \\\\ Semiconductor temperature sensors & Bandgap voltage of semiconductors (diodes, thermoelectric coolers) & \\(-\\)55 to +150 \\({}^{\\circ}\\)C & Typically 1–2\\% of reading & 0.3–0.5 K \\\\ Resistive temperature sensors (thermistors) & Temperature coefficient of resistance in semiconductors (typically NTC or PTC ceramics) & \\(-\\)200 to +800 \\({}^{\\circ}\\)C & Typically 0.1–1\\% of reading & 0.5–3 K \\\\ Capacitive temperature sensors & Temperature coefficient of capacitance in semiconductors or ferroelectric ceramics & \\(-\\)270 to +850 \\({}^{\\circ}\\)C & Typically 0.01–0.1\\% of reading & 0.1–0.3 K \\\\ Inductive temperature sensors & Temperature coefficient of inductance in metals or semiconductors & \\(-\\)260 to +570 \\({}^{\\circ}\\)C & Typically 0.01–0.1\\% of reading & 0.1–0.3 K \\\\ Optical temperature sensors & Thermal coefficient of optical properties (e.g., infrared absorptivity, refractive index) & \\(-\\)50 to +260 \\({}^{\\circ}\\)C & Typically 0.01–1\\% of reading & 0.1–5 K \\\\ \\hline \\hline \\end{tabular}\n\\end{table}\nTable 2: Properties of Temperature Sensors#### Light Intensity Sensors\n\nFor many applications, the illuminance on a surface or in an environment has to be measured (Table 3). Photodiodes offer a linear response over a wide range and can easily be integrated into electronic circuits. However, they require external amplifiers. For lower sensitivities or higher dynamic ranges, phototransistors are sufficient. Photoresistors have a high sensitivity but low accuracy due to their nonlinear behavior [20].\n\n#### Pressure Sensors\n\nFor many applications (e.g., in mechanical engineering), pressure has to be measured (Table 4). Strain gauges can measure very high pressures and offer an excellent linearity, but they have a relatively low sensitivity of about 0.1 mV/V/V [27]. Piezoelectric sensors offer high sensitivities, but they are not suitable for static pressure measurements because their electrical charge depends on the time derivative of the applied force. Capacitive pressure sensors are very common and can be used in a wide range from vacuum to several hundred bars with good linearity and accuracy [28].\n\n#### Gas Sensors\n\nFor many applications, it is important to detect or measure certain gases (Table 5). Chemoresistive gas sensors have low costs but a relatively high temperature dependence and sensitivity to humidity. For this reason, they are only suitable for monitoring concentrations of one particular gas type [30]. Metal oxide sensors offer very high sensitivities with short response times in a wide temperature range. However, their complex behavior requires special measurement circuits or calibration methods [31].\n\n\\begin{table}\n\\begin{tabular}{l l l l l} \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Photodiodes & PN junction of semiconductors & 0 to +150,000 Lux (lx) & Typically 0.1–1\\% & 0.3–30 lx \\\\ Phototransistors & Bipolar transistor with light-sensitive base & 0 to +100,000 Lux (lx) & Typically 1–5\\% & 0.3–10 lx \\\\ Photoresistors & Resistance of semiconductors that changes linearly with incident light intensity & 0 to +100,000 Lux (lx) & Typically 2–10\\% & 0.3–30 lx \\\\ \\hline \\end{tabular}\n\\end{table}\nTable 3: Properties of Light Intensity Sensors\n\n\\begin{table}\n\\begin{tabular}{l l l l l} \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Strain gauges & Piezoelectric strain gauge (piezo resistor) & 0 to +15 kN/mm\\({}^{2}\\) & Typically 0.1\\% of reading & 0.05–3\\% \\\\ Capacitive pressure sensors & Parallel-plate capacitor with deformable plates & \\(-\\)100,000 to +20,000 kN/mm\\({}^{2}\\) (vacuum to 200 bar) & Typically 0.5–3\\% of reading & 0.05–5\\% \\\\ Piezoelectric sensors & PZT or quartz crystal element with electrodes on its surface & \\(-\\)1 to +10 kN/mm\\({}^{2}\\) (vacuum to 10,000 bar) & Typically 0.5–3\\% of reading & 0.05–5\\% \\\\ Optical pressure sensors & Differential absorption or scattering of light by two media under pressure & 0 to +1000 kN/mm\\({}^{2}\\) (vacuum to 10 bar) & Typically 1–3\\% of reading & 0.05–5\\% \\\\ \\hline \\end{tabular}\n\\end{table}\nTable 4: Properties of Pressure Sensors#### Chemical Composition Sensors\n\nFor many applications, the chemical composition of gases or liquids has to be measured (Table 6). Electrochemical sensors are based on the principle that an electrochemical reaction between a sample and an electrolyte solution generates an electrical potential, which can be used as a measure for the concentration of one or several analytes. They offer low costs, high sensitivities, and good linearity in a wide range [32]. However, they have a limited temperature stability and require regular calibration due to their sensitivity to humidity, temperature, and other environmental factors.\n\n#### Acceleration Sensors\n\nFor many applications (e.g., in automotive engineering), acceleration has to be measured (Table 7). Piezoelectric accelerometers offer high sensitivities but are not suitable for static measurements due to their time-dependent electrical charge. For this reason, capacitive accelerometers are commonly used because they provide excellent linearity and accuracy over a wide range with low temperature dependence [33].\n\n\\begin{table}\n\\begin{tabular}{l l l l l} \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Electrochemical sensors & Sensing element that generates an electrical potential due to an electrochemical reaction with the sample and an electrolyte solution & 1 ppm to +100\\% (gas) & Typically 1–3\\% of reading & 0.5–5\\% \\\\ Optical chemical composition sensors & Differential absorption or scattering of light by two media under pressure & 1 ppm to +100\\% (gas) & Typically 2–5\\% of reading & 1–10\\% \\\\ \\hline \\end{tabular}\n\\end{table}\nTable 6: Properties of Chemical Composition Sensors\n\n\\begin{table}\n\\begin{tabular}{l l l l l} \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Electrochemical sensors (gas) & Sensing element that generates an electrical potential due to an electrochemical reaction with the sample and an electrolyte solution & 1 ppm to +100\\% (gas) & Typically 1–3\\% of reading & 0.5–5\\% \\\\ Optical chemical composition sensors (gas) & Differential absorption or scattering of light by two media under pressure & 1 ppm to +100\\% (gas) & Typically 2–5\\% of reading & 1–10\\% \\\\ Electrochemical sensors (liquid) & Sensing element that generates an electrical potential due to an electrochemical reaction with the sample and an electrolyte solution & 1 ppm to +100\\% (gas) & Typically 2–5\\% of reading & 1--10\\% \\\\ Optical chemical composition sensors (liquid) & Differential absorption or scattering of light by two media under pressure & 1 ppm to +100\\% (gas) & Typically 3--7\\% of reading & 3--15\\% \\\\ \\hline \\end{tabular}\n\\end{table}\nTable 5: Properties of Gas Sensors#### Flow Rate Sensors\n\nFor many applications, the flow rate of a liquid or gas has to be measured (Table 8). Differential pressure sensors can measure volumetric flow rates by measuring the pressure difference between two points in a pipe. They offer high accuracy but are only suitable for low and medium flow rates due to their limited frequency range [34]. Thermal mass flow rate sensors use heat transfer effects to determine the mass flow rate of a gas or liquid without any moving parts. However, they require calibration with respect to temperature and pressure [35].\n\n#### Level Sensors\n\nFor many applications (e.g., in process engineering), it is important to detect or measure levels of liquids or granular materials (Table 9). Ultrasonic sensors offer a wide measurement range, high accuracy, and good linearity due to their noncontact measurement principle. However, they are sensitive to temperature, humidity, and other environmental factors [36]. Capacitive level sensors provide excellent linearity and accuracy with low temperature dependence but require contact with the measured medium [37].\n\n#### Proximity Sensors\n\nFor many applications (e.g., in robotics), it is important to detect objects or surfaces without touching them (Table 10). Ultrasonic proximity sensors use high-frequency sound waves to measure distances based on echo time and amplitude [38]. Capacitive proximity sensors measure capacitance changes between two electrodes, which can be used as a measure for the distance to an object or surface. However, they require contact with the measured medium due to their noncontact measurement principle [39].\n\n\\begin{table}\n\\begin{tabular}{l l l l l} \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Differential pressure sensors & Pressure sensor that measures the pressure difference between two points in a pipe & 0 to +1 m/s (volumetric flow rate) & Typically 0.2–0.5\\% of reading & 0.1–0.3\\% \\\\ Thermal mass flow rate sensors & Sensing element that uses heat transfer effects to determine the mass flow rate of a gas or liquid & 0.01 to +50 kg/h (mass flow rate) & Typically 2–5\\% of reading & 1--10\\% \\\\ \\hline \\end{tabular}\n\\end{table}\nTable 8: Properties of Flow Rate Sensors#### Inclination Sensors\n\nFor many applications, it is important to measure angles or inclinations (Table 11). Tilt sensors use a pendulum mechanism to detect changes in the angle of tilt. They offer high accuracy and low power consumption but are sensitive to vibrations [40]. Angular acceleration sensors use piezoelectric or capacitive elements to measure angular accelerations, which can be used as a measure for inclination. However, they require regular calibration due to their sensitivity to humidity, temperature, and other environmental factors [41].\n\n\\begin{table}\n\\begin{tabular}{l l l l l} \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Ultrasonic proximity sensors & High-frequency sound waves to measure distances based on echo time and amplitude & 0 to +50 cm (distance) & Typically 1–2\\% of reading & 0.3--1.5\\% \\\\ Capacitive proximity sensors & Measures capacitance changes between two electrodes & 0 to +1 mm (distance) & Typically 1--3\\% of reading & 0.3--1.5\\% \\\\ \\hline \\end{tabular}\n\\end{table}\nTable 10: Properties of Proximity Sensors\n\n\\begin{table}\n\\begin{tabular}{l l l l l} \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Ultrasonic level sensors & High-frequency sound waves to measure distances based on echo time and amplitude & 0 to +5 m (distance) & Typically 0.5--1\\% of reading & 0.2--1.5\\% \\\\ Capacitive level sensors & Measures capacitance changes between two electrodes & 0 to +10 cm (distance) & Typically 1--3\\% of reading & 0.5--3\\% \\\\ \\hline \\end{tabular}\n\\end{table}\nTable 9: Properties of Level Sensors#### Rotational Speed Sensors\n\nFor many applications, it is important to measure rotational speeds or revolutions per minute (rpm) (Table 12). Optical rotary encoders use light barriers to detect the rotation of a shaft and determine its speed. They offer high accuracy and low power consumption but are sensitive to vibrations and require regular cleaning due to their susceptibility to dirt accumulation [42]. Inductive rotary encoders use an inductive principle to measure rotational speeds without any moving parts. However, they require a special winding pattern on the shaft and may cause electromagnetic interference [43].\n\n#### Temperature Sensors\n\nFor many applications, it is important to measure temperatures (Table 13). Resistive temperature detectors (RTDs) use changes in electrical resistance to determine temperatures. They offer high accuracy and long-term stability but are relatively expensive compared to other temperature sensors [44]. Thermocouples use the Seebeck effect to generate a voltage proportional to the temperature difference between two junctions. They are simple, rugged, and cost-effective but have lower accuracy than RTDs [45].\n\n\\begin{table}\n\\begin{tabular}{l l l l l} \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Optical rotary encoders & Light barriers to detect the rotation of a shaft and determine its speed & 0 to +12,000 rpm (rotational speed) & Typically 0.5–1\\% of reading & 0.1--0.3\\% \\\\ Inductive rotary encoders & Measures rotational speeds without any moving parts & 0 to +12,000 rpm (rotational speed) & Typically 1--3\\% of reading & 0.5--2\\% \\\\ \\hline \\end{tabular}\n\\end{table}\nTable 12: Properties of Rotational Speed Sensors#### Humidity Sensors\n\nFor many applications, it is important to measure humidity levels (Table 14). Capacitive humidity sensors use changes in capacitance to determine the amount of moisture in the air. They offer high accuracy and long-term stability but are relatively expensive compared to other humidity sensors [46]. Resistive humidity sensors use changes in electrical resistance to determine the amount of moisture in the air. They are simple, rugged, and cost-effective but have lower accuracy than capacitive humidity sensors [47].\n\n\\begin{table}\n\\begin{tabular}{l l l l l} \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Capacitive humidity sensors & Changes in capacitance to determine the amount of moisture in the air & 0 to +100\\% RH (humidity) & Typically 1--3\\% of reading & 1--5\\% \\\\ Resistive humidity sensors & Changes in electrical resistance to determine the amount of moisture in the air & 0 to +100\\% RH (humidity) & Typically 2--5\\% of reading & 2--10\\% \\\\ \\hline \\end{tabular}\n\\end{table}\nTable 14: Properties of Humidity Sensors\n\n\\begin{table}\n\\begin{tabular}{l l l l l} \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Resistive temperature detectors (RTDs) & Changes in electrical resistance to determine temperatures & -200 to +850°C (temperature) & Typically 0.1--0.3\\% of reading & 0.1--0.5\\% \\\\ Thermocouples & Generate a voltage proportional to the temperature difference between two junctions & -200 to +1800°C (temperature) & Typically 1--5\\% of reading & 2--5\\% \\\\ \\hline \\end{tabular}\n\\end{table}\nTable 13: Properties of Temperature Sensors#### Pressure Sensors\n\nFor many applications, it is important to measure pressures (Table 15). Strain gauge pressure sensors use changes in electrical resistance to determine the amount of force exerted on a diaphragm. They offer high accuracy and long-term stability but are relatively expensive compared to other pressure sensors [48]. Piezoelectric pressure sensors use the piezoelectric effect to generate a voltage proportional to the pressure applied. They are simple, rugged, and cost-effective but have lower accuracy than strain gauge pressure sensors [49].\n\n### Summary\n\nSensors are essential components of automation systems that convert physical or chemical quantities into electrical signals for further processing and control. There are various types of sensors available, each with their unique characteristics and applications. The selection of the appropriate sensor depends on factors such as measurement range, accuracy, response time, environmental conditions, cost, and compatibility with other system components.\n\nThis chapter presented an overview of the most common types of sensors used in automation systems, including position, force, temperature, pressure, flow rate, humidity, and rotational speed sensors. The working principles, characteristics, advantages, and disadvantages of each sensor type were discussed, along with their typical applications and selection criteria.\n\nThe chapter also provided practical examples of how sensors are used in real-world automation systems to measure and control various physical quantities. These examples demonstrated the importance of accurate and reliable sensing in ensuring the performance, safety, and efficiency of automated processes.\n\nIn conclusion, sensors play a critical role in automation systems by providing essential information about the state of the system and its environment. Understanding the different types of sensors available, their characteristics, advantages, and limitations is crucial for selecting and integrating appropriate sensing solutions into automation systems.\n\n\\begin{tabular}{l l l l l} \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Strain gauge pressure sensors & Changes in electrical resistance to determine the amount of force exerted on a diaphragm & 0 to +1,000 bar (pressure) & Typically 0.2--0.5\\% of reading & 0.1--0.3\\% \\\\ Piezoelectric pressure sensors & Generate a voltage proportional to the pressure applied & 0 to +1,000 bar (pressure) & Typically 1--5\\% of reading & 2--5\\% \\\\ \\hline \\end{tabular}\n\\end{table}\nTable 15: Properties of Pressure Sensors* [6] H. Ohm, The Galvanic Circuit Investigated Mathematically (Taylor and Francis, London, UK, 1891)\n\n_Peter C. Taylor and Kaveh Naderi_\n\n### Introduction\n\nAutomation systems often need to handle materials that are fluid or have a liquid-like consistency, such as fluids, slurries, pastes, or powders. These materials can be moved, controlled, mixed, or processed using pumps, valves, and piping in various applications such as chemical processing, pharmaceuticals, food and beverage production, water treatment, and oil and gas exploration [1]. In these cases, the fluid handling system must ensure that the material flows at a desired rate and direction with minimal losses due to leaks or spills.\n\nIn this chapter, we will discuss the principles and components of fluid handling systems used in automation applications. We will cover pumps, valves, piping, fittings, and seals, as well as flow measurement devices such as flow meters and pressure transducers. The chapter includes practical examples and best practices for designing, installing, maintaining, and troubleshooting fluid handling systems.\n\n### Pumps\n\nPumps are mechanical devices that convert rotational or linear motion into hydraulic energy to move liquids or fluids from one location to another [2]. They can be classified based on their working principle, such as positive displacement pumps, centrifugal pumps, and kinetic pumps.\n\nPositive displacement pumps use a mechanical action to displace a fixed volume of fluid with each stroke or revolution. The most common types are reciprocating pumps, rotary vane pumps, and gear pumps. Reciprocating pumps have a piston that moves back and forth in a cylinder to suck and push the fluid. Rotary vane pumps use rotors with radial vanes to create chambers that fill and empty as they rotate, displacing the fluid. Gear pumps have two intermeshing gears that trap and pump the fluid between them as they rotate.\n\nCentrifugal pumps convert kinetic energy into potential energy by accelerating a liquid using a rotating impeller. The fluid enters the center of the impeller, gets centrifugally flung to the outer periphery, and exits through an outlet port. Centrifugal pumps can be further classified into single-stage or multi-stage designs depending on the number of impellers used.\n\nKinetic pumps use the momentum of a fluid stream to create a pressure differential that moves the liquid. The most common types are jet pumps and ejectors, which use a high-velocity fluid jet to entrain and accelerate the fluid being pumped.\n\nPumps can also be classified based on their application, such as general service, high-pressure, high-temperature, or hazardous fluids. The selection of the appropriate pump for a specific application depends on factors such as flow rate, pressure head, fluid viscosity, temperature, corrosiveness, toxicity, and safety requirements.\n\nThe main parameters that describe the performance of a pump are its flow rate (Q), pressure head (H), power (P), efficiency (η), and NPSH (net positive suction head) [3]. The flow rate is the volume of fluid per unit time that the pump can deliver, typically expressed in liters per minute (L/min) or gallons per minute (GPM). The pressure head is the difference between the discharge pressure and the suction pressure, expressed in meters or feet of liquid column. The power is the energy required to operate the pump, usually measured in watts or horsepower. The efficiency is the ratio of the output power to the input power, expressed as a percentage. The NPSH is the minimum suction pressure required to prevent cavitation, which occurs when the pressure drops below the vapor pressure of the fluid, causing bubbles that can damage the pump and reduce its performance.\n\n### Valves\n\nValves are mechanical devices that control the flow rate, direction, and pressure of fluids in a piping system [4]. They consist of a body, a stem or rod, a disc or plug, an actuator, and a packing or seal to prevent leaks. The valve body houses the fluid path, while the stem or rod connects the disc or plug to the actuator, which can be manual, pneumatic, hydraulic, or electric.\n\nValves can be classified based on their function, such as shutoff, control, diversion, and safety valves. Shutoff valves are used to stop or start the flow of fluid by completely opening or closing the valve. Control valves regulate the flow rate, pressure, or direction of fluid by partially opening or closing the valve. Diversion valves distribute the fluid among multiple branches. Safety valves protect the system from overpressure or vacuum by releasing excess fluid when certain conditions are met.\n\nValves can also be classified based on their construction and operation, such as globe, ball, butterfly, plug, diaphragm, and needle valves [5]. Globe valves have a linear motion that moves the disc against a seat to regulate the flow rate. Ball valves use a spherical disc with an opening in the middle to allow or block the flow of fluid. Butterfly valves have a flat disc mounted on a rod perpendicular to the flow direction, which rotates 90 degrees to open or close the valve. Plug valves have a cylindrical plug with an axial hole that aligns or misaligns with the inlet and outlet ports when rotated. Diaphragm valves use a flexible diaphragm that separates the fluid from the actuator, providing a leak-free seal. Needle valves have a long tapered needle that screws into the seat to regulate the flow rate accurately.\n\nThe choice of valve for a specific application depends on factors such as flow rate, pressure drop, fluid properties, temperature, corrosiveness, toxicity, safety requirements, and cost. The design criteria for valves include their Cv value, which is the flow coefficient that relates the flow rate to the pressure drop across the valve, and their response time, accuracy, repeatability, and durability [6].\n\n### Piping\n\nPiping systems consist of pipes, fittings, couplings, flanges, gaskets, supports, and insulation that transport fluids from one location to another [7]. The design of piping systems must consider factors such as flow rate, pressure drop, fluid properties, temperature, corrosiveness, toxicity, safety requirements, and cost.\n\nPipes are long hollow cylinders made of various materials such as steel, stainless steel, iron, copper, plastic, or composite. They can be classified based on their shape, such as round, square, rectangular, or oval. The selection of the pipe material depends on factors such as compatibility with the fluid, pressure rating, temperature range, corrosion resistance, mechanical strength, and cost.\n\nFittings are devices that connect, branch, change direction, or terminate pipes. They can be classified based on their function, such as elbows, tees, couplings, unions, reducers, and caps. The selection of the fitting depends on factors such as size, material, pressure rating, temperature range, and cost.\n\nCouplings are devices that connect two pipes end-to-end. They can be classified based on their connection method, such as threaded, welded, flanged, or clamped. The selection of the coupling depends on factors such as size, material, pressure rating, temperature range, and ease of installation and removal.\n\nFlanges are devices that connect two pipes or components using bolts and gaskets. They can be classified based on their shape, such as flat face, raised face, ring joint, lap joint, and tongue-and-groove. The selection of the flange depends on factors such as size, material, pressure rating, temperature range, and compatibility with other components.\n\nGaskets are devices that seal the interface between two surfaces, such as flanges or valve seats. They can be made of various materials such as rubber, graphite, PTFE (polytetrafluoroethylene), or metallic composites. The selection of the gasket depends on factors such as pressure rating, temperature range, fluid compatibility, and durability.\n\nSupports are devices that hold pipes in place and prevent them from sagging, bending, or vibrating excessively. They can be classified based on their type, such as hangers, trunnions, rollers, saddles, clamps, or anchors. The selection of the support depends on factors such as pipe size, weight, orientation, and operating conditions.\n\nInsulation is a material that covers pipes to prevent heat loss or gain, reduce condensation, protect personnel from burns or frostbite, and reduce noise. It can be made of various materials such as fiberglass, calcium silicate, polyurethane foam, or mineral wool. The selection of the insulation depends on factors such as temperature range, thermal conductivity, moisture resistance, durability, and cost.\n\n### Fittings\n\nFittings are devices used to connect, redirect, or stop the flow of fluids in a piping system [8]. They can be classified based on their function, such as elbows, tees, couplings, unions, reducers, and caps. The selection of the fitting depends on factors such as size, material, pressure rating, temperature range, and cost.\n\nElbows are fittings used to change the direction of the flow by 90 or 45 degrees. They can be classified based on their shape, such as long radius, short radius, compact, mitre, concentric, eccentric, and swivel. The choice of elbow depends on factors such as pipe size, fluid velocity, pressure drop, space availability, and cost.\n\nTees are fittings used to split or combine the flow in three directions. They can be classified based on their connection method, such as welded, socket, threaded, flanged, or quick-connect. The choice of tee depends on factors such as pipe size, fluid properties, pressure drop, temperature range, and cost.\n\nCouplings are fittings used to connect two pipes end-to-end. They can be classified based on their connection method, such as threaded, welded, flanged, clamped, or compression. The choice of coupling depends on factors such as pipe size, material, pressure rating, temperature range, and ease of installation and removal.\n\nUnions are fittings used to connect two pipes using a male-female connection that can be disassembled without rotating the pipes. They can be classified based on their seal type, such as compression, O-ring, or gasket. The choice of union depends on factors such as pipe size, material, pressure rating, temperature range, and frequency of disassembly.\n\nReducers are fittings used to change the diameter of a pipe up or down. They can be classified based on their shape, such as concentric, eccentric, tapered, or stepped. The choice of reducer depends on factors such as pipe size, fluid velocity, pressure drop, space availability, and cost.\n\nCaps are fittings used to close the end of a pipe or a branch of a tee. They can be classified based on their connection method, such as welded, threaded, flanged, or quick-connect. The choice of cap depends on factors such as pipe size, material, pressure rating, temperature range, and cost.\n\n### Seals\n\nSeals are devices used to prevent leakage between two surfaces that move relative to each other [9]. They can be classified based on their function, such as static, reciprocating, or rotary. The choice of seal depends on factors such as fluid properties, pressure rating, temperature range, speed, durability, and cost.\n\nStatic seals are used when the two surfaces do not move relative to each other. They can be made of various materials such as rubber, plastic, graphite, PTFE (polytetrafluoroethylene), or metal. The most common types of static seals are O-rings, lip seals, and gaskets.\n\nO-rings are donut-shaped elastomeric seals that fit into a groove on one of the surfaces and compress when the two surfaces come together to form a leak-free seal. They can be made of various materials such as NBR (nitrile butadiene rubber), EPDM (ethylene propylene diene monomer), FKM (fluorocarbon elastomer), or silicone.\n\nLip seals are elastomeric or metallic seals that have a flat or tapered face that contacts the other surface and forms a leak-free seal. They can be made of various materials such as PTFE, carbon graphite, or polyurethane.\n\nGaskets are seals made of various materials such as rubber, paper, cardboard, cork, plastic, or metal. They are placed between the two surfaces and compressed when they come together to form a leak-free seal.\n\nReciprocating seals are used when the two surfaces move relative to each other in a linear or oscillatory manner. They can be classified based on their construction, such as packing, piston ring, or cup seal. The choice of reciprocating seal depends on factors such as speed, pressure, temperature, durability, and lubrication.\n\nPacking is a generic term used to describe various types of seals that consist of braided or solid elastomeric rings impregnated with lubricant that are inserted into a stuffing box around the shaft or rod. They can be made of various materials such as PTFE, graphite, leather, rubber, or polyurethane.\n\nPiston rings are seals used in cylinder liners to prevent leakage between the piston and the liner. They can be made of various materials such as cast iron, steel, ceramic, or carbon graphite.\n\nCup seals are seals that consist of a cup-shaped elastomeric or metallic element that fits around the shaft or rod and contacts the other surface when it rotates or oscillates. They can be made of various materials such as PTFE, rubber, polyurethane, or metal.\n\nRotary seals are used when the two surfaces move relative to each other in a circular or angular manner. They can be classified based on their construction, such as labyrinth, lip, or face seal. The choice of rotary seal depends on factors such as speed, pressure, temperature, durability, and lubrication.\n\nLabyrinth seals are seals that consist of a series of concentric grooves or rings on one or both surfaces that form a tortuous path for the leakage to flow through. They can be made of various materials such as steel, aluminum, brass, or plastic.\n\nLip seals are seals that consist of an elastomeric or metallic element with a flat or tapered face that contacts the other surface and forms a leak-free seal. They can be made of various materials such as PTFE, rubber, polyurethane, or metal.\n\nFace seals are seals that consist of two flat or curved surfaces that contact each other and form a leak-free seal by applying pressure and/or friction. They can be made of various materials such as carbon graphite, ceramic, metal, or engineering plastic.\n\n### Filters\n\nFilters are devices used to remove contaminants from fluids or gases [10]. They can be classified based on their function, such as liquid filter, air filter, or gas filter. The choice of filter depends on factors such as particle size, flow rate, pressure drop, temperature range, and cost.\n\nLiquid filters are used to remove solid particles or dissolved impurities from liquids. They can be classified based on their construction, such as depth filter, surface filter, or cartridge filter. The choice of liquid filter depends on factors such as particle size, flow rate, pressure drop, temperature range, and application.\n\nDepth filters are filters that consist of a porous material with a large surface area and a deep structure. They can remove small particles as well as dissolved impurities by trapping them inside the pores or adsorbing them on the surfaces. They can be made of various materials such as cellulose, glass fiber, polyester, or polypropylene.\n\nSurface filters are filters that consist of a thin layer of porous material with a small surface area and a shallow structure. They can remove larger particles by trapping them on the top of the layer. They can be made of various materials such as polyester, nylon, or PTFE (polytetrafluoroethylene).\n\nCartridge filters are filters that consist of a replaceable element with a large surface area and a small volume. They can remove both solid particles and dissolved impurities by trapping them inside the pores or adsorbing them on the surfaces. They can be made of various materials such as polyester, glass fiber, PTFE (polytetrafluoroethylene), or activated carbon.\n\nAir filters are used to remove solid particles or gaseous impurities from air. They can be classified based on their construction, such as panel filter, bag filter, or cartridge filter. The choice of air filter depends on factors such as particle size, flow rate, pressure drop, temperature range, and application.\n\nPanel filters are filters that consist of a flat sheet of porous material with a large surface area and a small thickness. They can remove larger particles by trapping them on the top of the layer. They can be made of various materials such as polyester, glass fiber, or PTFE (polytetrafluoroethylene).\n\nBag filters are filters that consist of a flexible container with a porous material inside. They can remove small particles as well as gaseous impurities by trapping them inside the pores or adsorbing them on the surfaces. They can be made of various materials such as polyester, glass fiber, or activated carbon.\n\nCartridge filters are filters that consist of a replaceable element with a large surface area and a small volume. They can remove both solid particles and gaseous impurities by trapping them inside the pores or adsorbing them on the surfaces. They can be made of various materials such as polyester, glass fiber, PTFE (polytetrafluoroethylene), or activated carbon.\n\nGas filters are used to remove solid particles or chemical impurities from gases. They can be classified based on their construction, such as coalescer filter, absorber, or scrubber. The choice of gas filter depends on factors such as particle size, flow rate, pressure drop, temperature range, and application.\n\nCoalescer filters are filters that consist of a porous material with a large surface area and a deep structure. They can remove small particles as well as liquid droplets by trapping them inside the pores or coalescing them on the surfaces. They can be made of various materials such as glass fiber, PTFE (polytetrafluoroethylene), or stainless steel.\n\nAbsorbers are filters that consist of a porous material with a large surface area and a deep structure. They can remove gaseous impurities by trapping them inside the pores or adsorbing them on the surfaces. They can be made of various materials such as activated carbon, silica gel, or alumina.\n\nScrubbers are filters that consist of a liquid spray nozzle with a large surface area and a shallow structure. They can remove gaseous impurities by dissolving them in the liquid or reacting with them chemically. They can be made of various materials such as stainless steel, glass fiber, or plastic.",
        "Metrics of Evaluation": " The principal ideas of this text are about the evaluation of models using four key metrics: accuracy, precision, recall, and the F1 score. These metrics are based on the True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN) values derived from the model's predictions.\n\n* **Accuracy** is the ratio of correct predictions to the total number of instances, providing an overall measure of how often the model is correct in its predictions.\n* **Precision** is defined as the proportion of true positive predictions out of all positive predictions, measuring the model's ability to correctly identify positive instances.\n* **Recall**, also known as sensitivity, measures the proportion of actual positive instances that were correctly identified, providing a measure of the model's ability to correctly identify positive instances.\n* The **F1 score** is the harmonic mean of precision and recall, giving equal weight to both metrics and ranges from 0 to 1. It is useful when dealing with imbalanced datasets as it takes both false positives and false negatives into account.\n\nThese metrics provide a comprehensive evaluation of the model's performance by considering both precision and recall, and the F1 score offers a balance between these two metrics, making it a better choice than accuracy when dealing with imbalanced datasets.\n\nAdditionally, the text includes a reference to a figure (Figure 2) showing a flow diagram of DistilBERT, but there are no principal ideas provided in the text related to this figure."
    },
    "Texto_3": {
        "3 Substitution-based in-context example optimization (SICO)": " The principal ideas of this text are:\n\n1. SICO is a system for generating human-like text.\n2. The process of creating a prompt for SICO involves extracting language features from human-written text using LLM, initializing and optimizing in-context examples, and combining these elements with a task instruction to create the final prompt.\n3. The optimization of the prompt is evaluated by an unspecified method.\n4. The text also provides more detail on each step of the SICO process, although this is not a principal idea.\n\nThe text does not contain any overarching arguments or themes, and the principal ideas listed above are simply a summary of the steps involved in creating a prompt for the SICO system.",
        "Prompt evaluation": " The principal ideas of the text are:\n\n1. The utility of a prompt in a natural language processing task is assessed by collecting a set of task inputs and concatenating each input with the prompt, which is then fed into a large language model (LLM).\n2. The output text from the LLM is classified by a proxy detector to predict the probability of it being AI-generated, denoted as \\(P_{AI}\\).\n3. The utility score of the prompt is defined as one minus the average predicted probability across all task inputs in the evaluation set.\n4. A higher utility score indicates that the prompt is better at generating non-AI-like text.\n5. The text also mentions SICO, a system for generating prompts for the question answering task, which uses the probability of AI-generation to indicate the likelihood of a given text being AI-generated.\n6. Once a SICO prompt is constructed, it serves as a template for users to insert various task inputs.",
        "Prompt Construction": " The text describes a method called SICO (Substitution-based In-Context Optimization) for optimizing language generation by a large language model (LLM). The main ideas are:\n\n1. Data collection: Creating a dataset \\(D\\) of task inputs and corresponding outputs generated by the LLM and humans, respectively. This dataset is used for prompt construction and is independent of the evaluation set \\(X_{eval}\\).\n2. Feature extraction: Using the LLM to extract distinct linguistic features of human-written text from pairs of AI-generated and human-written outputs from \\(D\\).\n3. In-context example optimization: Initializing in-context examples by paraphrasing AI-generated outputs using a text feature as input. The in-context output is then optimized iteratively to be less AI-like, maintaining semantic similarity through substitution and rephrasing techniques.\n4. Substitution types: Word-level substitution utilizing synonym sets constructed from WordNet, ensuring part-of-speech tags are maintained. Sentence-level substitution uses a paraphrasing instruction combined with the extracted feature to generate semantically similar sentences.\n5. Algorithm: SICO iteratively optimizes in-context outputs using greedy substitution and compares new prompts based on utility scores. The final prompt is returned after \\(N\\) iterations.",
        "SICO for Paraphrasing": " The principal ideas of this text are:\n\n1. There are two approaches for generating task output using SICO: SICO-Gen and SICO-Para.\n2. SICO-Gen directly generates the task output to evade detectors, while SICO-Para uses a two-step process of first producing an intermediate task output that is then paraphrased to successfully evade detectors.\n3. To switch from SICO-Gen to SICO-Para, there are two required adjustments: (1) the task input x is set to the AI-generated output text in D and X\\_eval, and (2) the task instruction p\\_{task} is modified to a paraphrasing instruction."
    },
    "Texto_4": {
        "3 RADAR: Methodology and Algorithms": " The principal ideas of the text are:\n\n1. Introduction of the RADAR framework, which consists of three neural-network-based language models: the target LM (θ), the detector (Dphi), and the paraphraser (Gσ).\n2. The training process involves four steps:\na. Data preparation by creating a corpus of AI-text (M) using document completion from human-text corpus (H) with the target LM (Tθ).\nb. Updating the paraphraser (Gphi) using Proximal Policy Optimization (PPO) and the reward from the detector (Dtheta).\nc. Updating the detector (Dtheta) using logistic loss function and human-text samples (Xh), original AI-text samples (Xm), and paraphrased AI-text samples (Xp).\nd. Validating and evaluating RADAR's performance using a test set of WebText during training and calculating the detection AUROC with Tθ for the evaluation dataset.\n3. Steps 2 to 3 are repeated until there is no improvement in the AUROC evaluated on the validation dataset, aiming to make the detector robust in detecting both original and paraphrased AI-text.",
        "Training Paraphraser via Clipped PPO with Entropy Penalty": " The principal ideas of the text are:\n\n1. RADAR is a system with a paraphraser model \\(\\mathcal{G}_{\bsigma}\\) that generates paraphrased text \\(x_{p}\\) from machine-generated input text \\(x_{m}\\).\n2. The paraphrasing process is viewed as a decision-making procedure, where the current state is the input text and the output text is the action taken.\n3. Reinforcement learning with Proximal Policy Optimization (PPO) is used to optimize \\(\\mathcal{G}_{\bsigma}\\), using reward feedback from the detector model \\(\\mathcal{D}_{\bphi}\\). The detector predicts the likelihood of \\(x_{p}\\) being human-written text.\n4. RADAR introduces Clipped PPO with Entropy Penalty (cppo-ep) to improve optimization, balancing between advantage (\\(L_{\rm A}\\)) and diversity (\\(L_{\rm E}\\)).\n5. The cppo-ep loss function is defined as a combination of the clipped surrogate objective (\\(L_{\rm A}\\)), which encourages paraphrases similar to human text, and an entropy term (\\(L_{\rm E}\\)), which encourages exploration of diverse generation policies.\n6. The expectation (\\(\\mathbb{E}\\)) in the cppo-ep loss function calculates the expected value over state-action pairs sampled from a policy.\n7. The importance sampling ratio \\(r({\bsigma}, x_{m}, x_{p})\\) represents the likelihood of a new policy \\(\\mathcal{G}_{\bsigma}\\) generating a given state-action pair compared to an old policy \\(\\mathcal{G}_{\bsigma'}\\).\n8. The advantage item \\(A(x_{p},{\bphi})\\) is obtained by normalizing the reward \\(R(x_{p},{\bphi})\\) across the entire PPO sample buffer \\(\\mathcal{B}\\), promoting paraphrases that resemble human text.\n9. The entropy term \\(S({\bsigma})\\) encourages exploration of diverse generation policies, preventing overfitting or degenerate solutions in the paraphrasing process.",
        "Training Detector via Reweighted Logistic Loss": " The principal ideas of this text are:\n\n1. In a typical GAN (Generative Adversarial Network) training process, the discriminator receives an equal number of positive and negative samples in each step, maintaining an in-batch sample balance.\n2. However, RADAR, a specific system, has an imbalance problem because it pairs each human-text sample with two AI-text samples: one original and one paraphrased.\n3. To address this imbalance, the authors use a reweighted logistic loss function to optimize the detector in RADAR. This loss function consists of three parts: one for human-text, one for original AI-text, and one for paraphrased AI-text.\n4. The coefficient \\(\\lambda\\) is introduced to adjust the proportion of AI-text components in the overall loss function, helping alleviate the effects of sample imbalance.",
        "RADAR Algorithm": " The principal ideas of the text are:\n\n1. RADAR is a training procedure for a paraphraser and detector.\n2. The training process includes data initialization, model initialization, and model training steps.\n3. Data initialization involves collecting human-written text, building a human-text corpus, selecting a target language model, building an AI-text corpus, creating a replay buffer, and building a validation dataset.\n4. Model initialization sets the detector and paraphraser as pretrained language models.\n5. During model training, the paraphraser generates a paraphrase of a sample from the human-text corpus and the AI-text corpus.\n6. A reward is collected based on the generated paraphrase, and an advantage function is computed using the reward.\n7. The replay buffer is filled with the sampled data and the corresponding advantage function value.\n8. The paraphraser's parameters are updated using the Proximal Policy Optimization (PPO) algorithm.\n9. In the evaluation phase, the detector predicts the likelihood of AI-text for any input instance.",
        "initialize the old policy \\(\\sigma^{\\prime}\\) as the current policy \\(\\sigma\\)": " The given text appears to be a part of a pseudocode or algorithm, specifically Algorithm 1, which is named \"RADAR: Robust AI-Text Detection via Adversarial Learning.\" Here are the principal ideas presented in this text:\n\n1. **Data processing:** The algorithm iterates through a dataset `B` consisting of tuples containing input data `(xh, xm, xp)` and corresponding labels `A(xp, φ)`.\n2. **Log probability computation:** For each tuple in the dataset `B`, the algorithm computes the log probability of the positive sample `xp` given the masked text `xm` using two generative models (`PGσ` and `PG'σ`).\n3. **Model updates based on computed probabilities:** The algorithm then updates one of the generative models, `PGσ`, based on the log probability computations performed in step 2. This update is done according to Eq. 2 mentioned in the algorithm.\n4. **Model parameter optimization:** After updating the model, the algorithm optimizes the parameters of a detector model, `Dφ`, using Eq. 3. This optimization step is also carried out for each tuple in the dataset.\n5. **Validation and best-performing models selection:** Once all tuples have been processed, the algorithm evaluates the performance of the detector model `Dφ` on a validation dataset `V`. It selects the best-performing detector model (highest AUROC value) as `Dphi_best` along with its corresponding paraphraser model (`Gsigma_best`).\n6. **Returning the optimized models:** Finally, the algorithm returns the best-performing detector and paraphraser models.\n\nOverall, this text describes an iterative process of data processing, probability computation, model updates, parameter optimization, validation, and selection for a pair of generative and detector models in the context of text detection via adversarial learning."
    }
}